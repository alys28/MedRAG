{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cohere / OpenAI / Claude embeddings \n",
    "# Weaviate Database\n",
    "# Step 0: Llama-Index / Langchain for indexing\n",
    "\n",
    "\n",
    "# sparse (BM-25) vs dense (Semantic) retrieval\n",
    "\n",
    "\n",
    "# The textbooks have already been chunked, so we need to do indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need for document / text splitting since the dataset has already done that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello eversif sdjfkal fjdlsaf sdfnj asfdjl sdfnjsndfs\n",
      " sjdlf sdfnjs d'\n",
      "  sdjf\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"demo.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing it out\n",
    "x = embeddings.embed_query(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and add all the doc strings\n",
    "import json\n",
    "def compile_docs(chunks_dir) -> list:\n",
    "    arr = []\n",
    "    current_dir = os.getcwd()\n",
    "    for file in os.listdir(chunks_dir):\n",
    "        with open(os.path.join(chunks_dir, file)) as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                # Parse the JSON data from the line\n",
    "                d = json.loads(line)\n",
    "                arr.append(d)\n",
    "    return arr\n",
    "docs = compile_docs(\"textbooks/chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=os.getenv(\"WCS_URL\"),  # Replace with your Weaviate Cloud URL\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCS_API_KEY\")),  # Replace with your Weaviate Cloud key\n",
    "    headers={'X-OpenAI-Api-key': os.getenv(\"OPENAI_API_KEY\")}  # Replace with your OpenAI API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_batches_docs(docs, collection_name) -> None:\n",
    "    collection = client.collections.get(collection_name)\n",
    "    with collection.batch.dynamic() as batch:\n",
    "        old_data = \"\"\n",
    "        # Docs to check: Neurology_Adams\n",
    "        for data in docs:\n",
    "            if old_data != data[\"title\"]:\n",
    "                print(data[\"title\"])\n",
    "                old_data = data[\"title\"]\n",
    "            batch.add_object(\n",
    "                properties={\"title\": data[\"title\"], \"content\":data[\"content\"]},\n",
    "                vector= embeddings.embed_query(data[\"content\"]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathoma_Husain\n",
      "Pathology_Robbins\n",
      "Anatomy_Gray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aly/opt/miniconda3/envs/hamming_ai_env/lib/python3.11/site-packages/grpc/aio/_call.py:577: ResourceWarning: unclosed <ssl.SSLSocket fd=78, family=2, type=1, proto=0, laddr=('192.168.2.17', 58894), raddr=('34.149.137.116', 443)>\n",
      "  serialized_response = await self._cython_call.unary_unary(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstentrics_Williams\n",
      "Cell_Biology_Alberts\n",
      "Surgery_Schwartz\n"
     ]
    }
   ],
   "source": [
    "# import_batches_docs(docs, \"Medical_RAG_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_RAG_collection = client.collections.get(\"Medical_RAG_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out some features (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "# response = medical_RAG_collection.query.near_text(\n",
    "#     query=\"What is anatomy? Anatomy includes those structures that can be seen grossly (without the aid of magnification) and microscopically (with the aid of magnification). Typically, when used by itself, the term anatomy tends to mean gross or macroscopic anatomy\\u2014that is, the study of structures that can be seen without using a microscopic. Microscopic anatomy, also called histology, is the study of cells and tissues using a microscope. Anatomy forms the basis for the practice of medicine. Anatomy leads the physician toward an understanding of a patient\\u2019s disease, whether he or she is carrying out a physical examination or using the most advanced imaging techniques. Anatomy is also important for dentists, chiropractors, physical therapists, and all others involved in any aspect of patient treatment that begins with an analysis of clinical signs. The ability to interpret a clinical observation correctly is therefore the endpoint of a sound anatomical understanding.\",\n",
    "#     limit=2,\n",
    "#     # target_vector=\"title_country\",  # Specify the target vector for named vector collections\n",
    "#     # return_metadata=MetadataQuery(distance=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggregateReturn(properties={}, total_count=114397)\n"
     ]
    }
   ],
   "source": [
    "agg = medical_RAG_collection.aggregate.over_all()\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'severe symptoms or circumstances in which other processes, e.g., infection, are strongly suspected. Nasal oxygen should be used as appropriate to protect arterial saturation. Most crises resolve in 1–7 days. Use of blood transfusion should be reserved for extreme cases: transfusions do not shorten the duration of the crisis.', 'title': 'InternalMed_Harrison'}\n"
     ]
    }
   ],
   "source": [
    "response = medical_RAG_collection.query.fetch_objects(\n",
    "    include_vector=True,\n",
    "    limit=1\n",
    ")\n",
    "print(response.objects[0].properties)\n",
    "# print(response.objects[0].vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM-25 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object(uuid=_WeaviateUUIDInt('2c4037b2-63d4-48c1-9ec0-6acc3c5e1a9b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'content': 'Obsessive-compulsive features, both related and unrelated to food, are often prominent. Most individuals with anorexia nervosa are preoccupied with thoughts of food. Some col- lect recipes or hoard food. Observations of behaviors associated with other forms of star- vation suggest that obsessions ancl compulsions related to food may be exacerbated by undemutrition. When individuals with anorexia nervosa exhibit obsessions and compul- sions that are not related to food, body shape, or weight, an additional diagnosis of obses- sive-compulsive disorder (OCD) may be warranted.', 'title': 'Psichiatry_DSM-5'}, references=None, vector={}, collection='Medical_RAG_Data')\n"
     ]
    }
   ],
   "source": [
    "response = medical_RAG_collection.query.bm25(\n",
    "    query=\"food\",\n",
    "    limit=1,\n",
    "    query_properties=[\"content\"],\n",
    ")\n",
    "print(response.objects[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object(uuid=_WeaviateUUIDInt('49e8f90a-84c6-4fa0-9f02-11dc97806fbb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=0.18653613328933716, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'content': 'The bones of the gluteal region and the thigh are the pelvic bone and the femur (Fig. 6.8). The large ball and socket joint between these two bones is the hip joint. The femur is the bone of the thigh. At its distal end, its major weight-bearing articulation is with the tibia, but it also articulates anteriorly with the patella (knee cap). The patella is the largest sesamoid bone in the body and is embedded in the quadriceps femoris tendon. The joint between the femur and tibia is the principal articulation of the knee joint, but the joint between the patella and femur shares the same articular cavity. Although the main movements at the knee are flexion and extension, the knee joint also allows the femur to rotate on the tibia. This rotation contributes to “locking” of the knee when fully extended, particularly when standing. The leg contains two bones: The tibia is medial in position, is larger than the laterally positioned fibula, and is the weight-bearing bone.', 'title': 'Anatomy_Gray'}, references=None, vector={}, collection='Medical_RAG_Data')\n"
     ]
    }
   ],
   "source": [
    "response = medical_RAG_collection.query.near_vector(\n",
    "    near_vector=embeddings.embed_query(\"What is the biggest bone in the body?\"), # your query vector goes here\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "print(response.objects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also search with images. Could be useful for Multimodal benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Near Text Search (cannot be done with what I currently have set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.Collection at 0x3131a8950>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate.classes as wvc\n",
    "client.collections.create(\n",
    "    \"Test\",\n",
    "    properties=[\n",
    "        wvc.config.Property(name=\"title\", data_type=wvc.config.DataType.TEXT),\n",
    "        wvc.config.Property(name=\"content\", data_type=wvc.config.DataType.TEXT),\n",
    "    ],\n",
    "    \n",
    "    vectorizer_config=[ # NEED TO SPECIFY THIS FOR NEAR TEXT TO WORK\n",
    "        wvc.config.Configure.NamedVectors.text2vec_openai(\n",
    "            name=\"embeddings\",\n",
    "            source_properties=[\"content\"],\n",
    "            vectorize_collection_name=False,\n",
    "            vector_index_config=wvc.config.Configure.VectorIndex.hnsw(),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histology_Ross\n"
     ]
    }
   ],
   "source": [
    "import_batches_docs(docs[0:2], \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggregateReturn(properties={}, total_count=2)\n"
     ]
    }
   ],
   "source": [
    "test = client.collections.get(\"Test\")\n",
    "agg = test.aggregate.over_all()\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('cd518dcc-e038-451e-84ea-689ef83b11f0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'Histology_Ross', 'content': 'The objective of a histology course is to lead the student to understand the microanatomy of cells, tissues, and organs and to correlate structure with function.'}, references=None, vector={}, collection='Test')])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = test.query.near_text(\n",
    "    query=\"anatomy\",\n",
    "    limit=1,\n",
    "    # target_vector=\"title_country\",  # Specify the target vector for named vector collections\n",
    "    # return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template import *\n",
    "class RAG_System:\n",
    "    def __init__(self, limit=5, retrieval_method=\"dense\", collection_name=\"Medical_RAG_Data\"):\n",
    "        self.limit = limit\n",
    "        self.retrieval_method = retrieval_method.lower()\n",
    "        self.client = weaviate.connect_to_wcs(\n",
    "            cluster_url=os.getenv(\"WCS_URL\"),  # Replace with your Weaviate Cloud URL\n",
    "            auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCS_API_KEY\")),  # Replace with your Weaviate Cloud key\n",
    "            headers={'X-OpenAI-Api-key': os.getenv(\"OPENAI_API_KEY\")}  # Replace with your OpenAI API key\n",
    "        )\n",
    "        self.collection = self.client.collections.get(collection_name)\n",
    "    def answer_question(self, query, options, rag=False) -> dict:\n",
    "        '''\n",
    "        query (str): question to be answered\n",
    "        options (Dict[str, str]): options to be chosen from\n",
    "        k (int): number of snippets to retrieve\n",
    "        save_dir (str): directory to save the results\n",
    "        '''\n",
    "        if options is not None:\n",
    "            options = '\\n'.join([key+\". \"+options[key] for key in sorted(options.keys())])\n",
    "        else:\n",
    "            options = ''\n",
    "        if rag:\n",
    "            if self.retrieval_method == \"dense\":\n",
    "                response = self.collection.query.near_vector(\n",
    "                            near_vector=embeddings.embed_query(query), # your query vector goes here\n",
    "                            limit=self.limit,\n",
    "                            return_metadata=MetadataQuery(distance=True)\n",
    "                        )\n",
    "            elif self.retrieval_method == \"sparse\":\n",
    "                response = self.collection.query.bm25(\n",
    "                                query=query,\n",
    "                                limit=self.limit,\n",
    "                                query_properties=[\"content\"],\n",
    "                            )\n",
    "            context = \"\"\n",
    "            for i in range(len(response.objects)):\n",
    "                context += response.objects[i].properties[\"content\"]\n",
    "                context += \"\\n\"\n",
    "            prompt_medrag = general_medrag.render(context=context, question=question, options=options)\n",
    "            messages=[\n",
    "                    {\"role\": \"system\", \"content\": general_medrag_system},\n",
    "                    {\"role\": \"user\", \"content\": prompt_medrag}\n",
    "            ]\n",
    "            print(messages)\n",
    "        else:\n",
    "            prompt_cot = general_cot.render(context=context, question=question, options=options)\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": general_cot_system},\n",
    "                {\"role\": \"user\", \"content\": prompt_cot}\n",
    "            ]\n",
    "            print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys = Rag_System()\n",
    "sys.answer_question(\"What is the biggest bone in the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hamming_ai_env] *",
   "language": "python",
   "name": "conda-env-hamming_ai_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
